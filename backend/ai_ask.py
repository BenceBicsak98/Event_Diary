from fastapi import APIRouter
from pydantic import BaseModel
import os, threading, requests, chromadb
from chromadb.config import Settings
from sentence_transformers import SentenceTransformer

router = APIRouter()
_index_started = False
OLLAMA_HOST = os.getenv("OLLAMA_HOST", "http://ollama:11434")

# === Modell √©s Chroma inicializ√°l√°s ===
embedder = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')
chroma_client = chromadb.Client(Settings(persist_directory="./chromadb"))
collection = chroma_client.get_or_create_collection("docs")

# Egyszer≈± mem√≥riat√°rol√≥ (k√©s≈ëbb lehet user sessionh√∂z k√∂tni)
conversation_history = []

# === Helper f√ºggv√©nyek ===
def load_documents(folder_path="./documents"):
    docs = []
    for filename in os.listdir(folder_path):
        if filename.endswith(".txt"):
            with open(os.path.join(folder_path, filename), "r", encoding="utf-8") as f:
                content = f.read().replace("\n", " ").replace("  ", " ").strip()
                docs.append({"name": filename, "content": content})
    return docs

def chunk_text(text, chunk_size=500, overlap=50):
    chunks, start = [], 0
    while start < len(text):
        end = start + chunk_size
        chunks.append(text[start:end])
        start += chunk_size - overlap
    return chunks

def ensure_index():
    if len(collection.get()["ids"]) == 0:
        print("üìö Index √ºres, dokumentumok feldolgoz√°sa...")
        docs = load_documents()
        for doc in docs:
            chunks = chunk_text(doc["content"])
            for i, chunk in enumerate(chunks):
                emb = embedder.encode(chunk).tolist()
                collection.add(
                    ids=[f"{doc['name']}_{i}"],
                    documents=[f"{doc['name']}: {chunk}"],
                    metadatas=[{"source": doc["name"]}],
                    embeddings=[emb]
                )
        print("‚úÖ Index l√©trehozva.")

def ensure_index_background():
    global _index_started
    if not _index_started:
        _index_started = True
        threading.Thread(target=ensure_index, daemon=True).start()
        print("üß† Dokumentum indexel√©s fut a h√°tt√©rben...")

ensure_index_background()

# === Keres√©s √©s v√°lasz ===
def search_relevant_chunks(question, top_k=6):
    q_emb = embedder.encode(question).tolist()
    results = collection.query(query_embeddings=[q_emb], n_results=top_k)
    return results["documents"][0] if results["documents"] else []

def ask_ollama(question: str):
    chunks = search_relevant_chunks(question)
    context = "\n\n".join(chunks)

    # üîÅ Legut√≥bbi 5 √ºzenet kontextusk√©nt
    history_context = "\n".join(
        [f"Felhaszn√°l√≥: {msg['user']}\nAsszisztens: {msg['bot']}" for msg in conversation_history[-5:]]
    )

    prompt = f"""
Te egy magyar nyelv≈± szak√©rt≈ë asszisztens vagy, aki dokumentumok alapj√°n v√°laszol.

üß© Szab√°lyok:
- Mindig magyarul v√°laszolj.
- Csak a dokumentumr√©szletekre t√°maszkodj.
- Ha nincs relev√°ns inform√°ci√≥: "Nem tal√°lhat√≥ a dokumentumban."
- A besz√©lget√©s folyamatoss√°g√°t tartsd fenn: vedd figyelembe a kor√°bbi k√©rd√©seket is.
- L√©gy r√∂vid, pontos, logikus.

üìÑ Dokumentumr√©szletek:
{context}

üí¨ Kor√°bbi besz√©lget√©s:
{history_context}

‚ùì Aktu√°lis k√©rd√©s:
{question}

üß† V√°lasz (magyarul):
"""

    response = requests.post(
        f"{OLLAMA_HOST}/api/generate",
        json={"model": "llama3:8b-instruct-q4_0", "prompt": prompt, "stream": False},
        timeout=120
    )

    if response.status_code != 200:
        print("‚ö†Ô∏è Ollama API hiba:", response.text)
        return "‚ö†Ô∏è Hiba az Ollama API h√≠v√°sakor"

    data = response.json()
    answer = data.get("response", "").strip() or "‚ö†Ô∏è √úres v√°lasz √©rkezett."

    # üß© Mentj√ºk a besz√©lget√©st
    conversation_history.append({"user": question, "bot": answer})

    return answer

# === API v√©gpont ===
class Question(BaseModel):
    question: str

@router.post("/ask")
async def ask_api(q: Question):
    ensure_index_background()
    answer = ask_ollama(q.question)
    print(f"üß† K√©rd√©s: {q.question}")
    print(f"üí¨ V√°lasz: {answer}")
    return {"answer": answer}
